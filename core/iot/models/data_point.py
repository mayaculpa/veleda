import uuid
from datetime import timedelta, datetime, timezone
from typing import List, Dict, Any

from django.db import models, IntegrityError, transaction
from django.db.models.functions import TruncDay, TruncHour
from django.utils.dateparse import parse_datetime
from graphene.types.datetime import Date
from graphene.types.uuid import UUID


from iot.models.peripheral import PeripheralComponent


class DataPointType(models.Model):
    """The type of data stored and the unit the value is stored as."""

    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False,)
    name = models.CharField(
        max_length=50, help_text="The name, e.g., air temperature or acidity."
    )
    unit = models.CharField(
        max_length=20, help_text="The unit of the value, e.g., °C or pH."
    )

    def __str__(self):
        return f"{self.name} in {self.unit}"


class DataPointManager(models.Manager):
    """Handles telemetry messages for the DataPoint class"""

    def from_telemetry(self, message: Dict) -> List["DataPoint"]:
        """Create data points from a telemetry message. Raises ValueError on error"""

        # Get, parse and validate the time
        time = message.get("time", datetime.now(timezone.utc))
        time = self.model.to_timezone_datetime(time)

        try:
            peripheral_id = message["peripheral"]
            data_points: List["DataType"] = []
            for data_point in message["data_points"]:
                data_points.append(
                    self.model(
                        value=data_point["value"],
                        time=time,
                        data_point_type_id=data_point["data_point_type"],
                        peripheral_component_id=peripheral_id,
                    )
                )
                # Smear time to avoid integriy errors
                time += timedelta(microseconds=1)
        except KeyError as err:
            raise ValueError(f"Missing property {err}") from err
        self.bulk_create(data_points)
        return data_points

    def by_day(
        self,
        peripheral_component_id: UUID,
        data_point_type_id: UUID,
        from_date: Date,
        before_date: Date,
    ) -> "DataPoint":
        """Aggregates data points by day for a specific date range for the specified
           peripheral and data point type."""

        series = self.model.objects.filter(
            peripheral_component_id=peripheral_component_id,
            data_point_type_id=data_point_type_id,
        )
        if from_date:
            series = series.filter(time__date__gte=from_date)
        if before_date:
            series = series.filter(time__date__lt=before_date)
        series = (
            series.annotate(day=TruncDay("time"))
            .values("day")
            .annotate(
                avg=models.Avg("value"),
                min=models.Min("value"),
                max=models.Max("value"),
            )
            .order_by("day")
        )[:50]
        return list(series)

    def by_hour(
        self,
        peripheral_component_id: UUID,
        data_point_type_id: UUID,
        from_time: Date,
        before_time: Date,
    ) -> "DataPoint":
        """Aggregates data points by day for a specific date range for the specified
           peripheral and data point type."""

        series = self.model.objects.filter(
            peripheral_component_id=peripheral_component_id,
            data_point_type_id=data_point_type_id,
        )
        if from_time:
            series = series.filter(time__gte=from_time)
        if before_time:
            series = series.filter(time__lt=before_time)
        series = (
            series.annotate(time_hour=TruncHour("time"))
            .values("time_hour")
            .annotate(
                avg=models.Avg("value"),
                min=models.Min("value"),
                max=models.Max("value"),
            )
            .order_by("time_hour")
        )[:50]
        return list(series)


class DataPoint(models.Model):
    """Data points generated by peripherals, described by the data point type."""

    objects = DataPointManager()

    time = models.DateTimeField(primary_key=True, default=datetime.now)
    peripheral_component = models.ForeignKey(
        PeripheralComponent,
        on_delete=models.CASCADE,
        related_name="data_point_set",
        help_text="The peripheral that generated the data point.",
    )
    data_point_type = models.ForeignKey(
        DataPointType,
        on_delete=models.CASCADE,
        related_name="data_point_set",
        help_text="The type of data recorded and its unit.",
    )
    value = models.FloatField(
        help_text="The value of the data given by the data point type and peripheral."
    )

    class Meta:
        ordering = ["-time"]

    def save(self, *args, **kwargs):  # pylint: disable=signature-differs
        # If it is a 'naive' datetime, no timezone info, raise an error
        self.time = self.to_timezone_datetime(self.time)
        self._save_and_smear_timestamp(*args, **kwargs)

    def _save_and_smear_timestamp(self, *args, **kwargs):
        """Recursivly try to save by incrementing the timestamp on duplicate error"""

        try:
            with transaction.atomic():
                super().save(*args, **kwargs)
        except IntegrityError as exception:
            # Only handle the error:
            #   psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "1_1_farms_sensorreading_pkey"
            #   DETAIL:  Key ("time")=(2020-10-01 22:33:52.507782+00) already exists.
            if all(k in exception.args[0] for k in ("Key", "time", "already exists")):
                # Increment the timestamp by 1 µs and try again
                self.time = self.time + timedelta(microseconds=1)
                self._save_and_smear_timestamp(*args, **kwargs)

    @staticmethod
    def to_timezone_datetime(raw_time: Any) -> datetime:
        """Try to convert it to a valid datetime with timezone"""

        if isinstance(raw_time, datetime):
            time = raw_time
        else:
            if isinstance(raw_time, str):
                if (time := parse_datetime(raw_time)) is None:
                    raise ValueError(f"Invalid time: {raw_time}")
            else:
                raise ValueError(f"Unsupported time type: {raw_time}")
        if time.tzinfo is None or time.tzinfo.utcoffset(time) is None:
            raise ValueError("Time does not include timezone")
        return time

    def __str__(self):
        return f"{self.value} {self.data_point_type.unit} from {self.peripheral_component.site_entity.name}"
